{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e1be55d",
   "metadata": {},
   "source": [
    "# Logistic Regression Notebook\n",
    "-------\n",
    "We will use Social_Network_Ads.csv dataset in this notebook.\n",
    "\n",
    "The dataset has information on customers, and whether they bought a certain product or not.\n",
    "\n",
    "In this notebook, we will first implement Logistic Rregression from scratch, then use sklearn [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "\n",
    "We will show how to easily normalize you data using sklearn, and calculate the [confusion matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2977c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e805308",
   "metadata": {},
   "source": [
    "## 1. Read Data & Clean it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79f0c61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>15691863</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>41000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>15706071</td>\n",
       "      <td>Male</td>\n",
       "      <td>51</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>15654296</td>\n",
       "      <td>Female</td>\n",
       "      <td>50</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>15755018</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>33000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>15594041</td>\n",
       "      <td>Female</td>\n",
       "      <td>49</td>\n",
       "      <td>36000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0    15624510    Male   19            19000          0\n",
       "1    15810944    Male   35            20000          0\n",
       "2    15668575  Female   26            43000          0\n",
       "3    15603246  Female   27            57000          0\n",
       "4    15804002    Male   19            76000          0\n",
       "..        ...     ...  ...              ...        ...\n",
       "395  15691863  Female   46            41000          1\n",
       "396  15706071    Male   51            23000          1\n",
       "397  15654296  Female   50            20000          1\n",
       "398  15755018    Male   36            33000          0\n",
       "399  15594041  Female   49            36000          1\n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/Social_Network_Ads.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e57b0c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User ID             int64\n",
       "Gender             object\n",
       "Age                 int64\n",
       "EstimatedSalary     int64\n",
       "Purchased           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b63a1b",
   "metadata": {},
   "source": [
    "## 2. Split Data\n",
    "----\n",
    "Notice that we want X to be only the Age and Estimated Salary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34008640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>46</td>\n",
       "      <td>41000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>51</td>\n",
       "      <td>23000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>50</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>36</td>\n",
       "      <td>33000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>49</td>\n",
       "      <td>36000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  EstimatedSalary\n",
       "0     19            19000\n",
       "1     35            20000\n",
       "2     26            43000\n",
       "3     27            57000\n",
       "4     19            76000\n",
       "..   ...              ...\n",
       "395   46            41000\n",
       "396   51            23000\n",
       "397   50            20000\n",
       "398   36            33000\n",
       "399   49            36000\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.loc[:, 'Age':'EstimatedSalary']\n",
    "Y = df['Purchased']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "630d5db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 2) (300,)\n",
      "(100, 2) (100,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=0)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20a14cb",
   "metadata": {},
   "source": [
    "### Additional Part!\n",
    "-----\n",
    "It's better to standardize/normalize your data before giving it to any regression model.\n",
    "\n",
    "What normalize does can be shown in this image:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33652c32",
   "metadata": {},
   "source": [
    "![title](images/standardize.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a07b383",
   "metadata": {},
   "source": [
    "We can use [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) function from sklearn right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b162b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29cced7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.80480212,  0.50496393],\n",
       "       [-0.01254409, -0.5677824 ],\n",
       "       [-0.30964085,  0.1570462 ],\n",
       "       [-0.80480212,  0.27301877],\n",
       "       [-0.30964085, -0.5677824 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "X_test[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587570b7",
   "metadata": {},
   "source": [
    "## 3. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d87866e",
   "metadata": {},
   "source": [
    "## Part One: From scratch\n",
    "In the first part of the notebook, we will implement Linear Regression **from scratch**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eeee1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,) (300,)\n"
     ]
    }
   ],
   "source": [
    "X1_train = X_train[:, 0]\n",
    "X2_train = X_train[:, 1]\n",
    "print(X1_train.shape, X2_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a74c6529",
   "metadata": {},
   "outputs": [],
   "source": [
    "w0, w1, w2 = 0, 0, 0\n",
    "lr = 0.0001\n",
    "epochs = 1000\n",
    "n = float(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0650af64",
   "metadata": {},
   "source": [
    "logistic function is:\n",
    "y = sigmoid_function(w0 + w1 * x1 + w2 * x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b55ed13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z = h_theta(x)\n",
    "# output range [0,1]\n",
    "sigmoid_func = lambda z: 1.0 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f89712b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "#### IGNORE THIS CELL ####\n",
    "##########################\n",
    "def cost_funct(X, y, Theta):\n",
    "    hypothesis = sigmoid(X * omega)\n",
    "    zero = np.multiply(y, np.log2(hypothesis))\n",
    "    one = np.multiply((1 - y), np.log2(1 - hypothesis))\n",
    "    return (-1/len(X)) * np.sum(zero + one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91ec1a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    # Ypred = w0 + w1 * X1 + w2 * X2\n",
    "    # so, Y_pred is in range [0,1]\n",
    "    Y_pred = sigmoid_func(w0 + w1 * X1_train + w2 * X2_train)\n",
    "    \n",
    "    Dw0 = 1/n * np.sum((Y_pred - Y_train))\n",
    "    Dw1 = 1/n * np.sum(X1_train * (Y_pred - Y_train))\n",
    "    Dw2 = 1/n * np.sum(X2_train * (Y_pred - Y_train))\n",
    "    \n",
    "    w0 = w0 - lr * Dw0\n",
    "    w1 = w1 - lr * Dw1\n",
    "    w2 = w2 - lr * Dw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed69497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function just to map probability to either 0 or 1. rint rounds a float value to the closest integer\n",
    "classify_func = lambda x: np.rint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f30a629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49717783 0.49865989 0.49430621 0.50049695 0.50059869]\n",
      "[0. 0. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "X1_test = X_test[:, 0]\n",
    "X2_test = X_test[:, 1]\n",
    "print(Y_pred[0:5])\n",
    "# calculate Y_pred probability based on X_test now, not X_train\n",
    "Y\n",
    "Y_pred = classify_func(Y_pred)\n",
    "Y_pred[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b766ce36",
   "metadata": {},
   "source": [
    "## 4. Evaluate Model (Confusion Matrix)\n",
    "----\n",
    "After getting the confusion matrix, we will calculate accuracy, recall, precision and f1 score as following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebe640f",
   "metadata": {},
   "source": [
    "![title](images/confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "100907a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [100, 300]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\RADWAK~1\\AppData\\Local\\Temp/ipykernel_8828/1067389975.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m     \"\"\"\n\u001b[1;32m--> 307\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    333\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [100, 300]"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc95d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (cm[0,0] + cm[1,1]) * 1.0 / (len(Y_pred))\n",
    "print(\"Accuracy = %.2f%%\" % (accuracy * 100))\n",
    "\n",
    "recall = cm[0,0] * 1.0 / (cm[0,0] + cm[0,1])\n",
    "print(\"Recall = %.2f%%\" % (recall * 100))\n",
    "\n",
    "precision = cm[0,0] * 1.0 / (cm[0,0] + cm[1,0])\n",
    "print(\"Precision = %.2f%%\" % (precision * 100))\n",
    "\n",
    "f1 = (2 * precision * recall) / (precision + recall)\n",
    "print(\"F1 Score = %.2f%%\" % (f1 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a236127",
   "metadata": {},
   "source": [
    "## Part Two: Using Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ad6d0e",
   "metadata": {},
   "source": [
    "Notice that Y is categorial; contains values of 0 and 1. Hence, it needn't be normalized.\n",
    "\n",
    "Now, back to the model.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2acf1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(random_state=0)\n",
    "logistic_model = logistic_model.fit(X_train, Y_train)\n",
    "Y_pred = logistic_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86d5115",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1be0355",
   "metadata": {},
   "source": [
    "This means that 65+24 elements were predicted correctly, and 8+3 are predicted wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8b4f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (cm[0,0] + cm[1,1]) * 1.0 / (len(Y_pred))\n",
    "print(\"Accuracy = %.2f%%\" % (accuracy * 100))\n",
    "\n",
    "recall = cm[0,0] * 1.0 / (cm[0,0] + cm[0,1])\n",
    "print(\"Recall = %.2f%%\" % (recall * 100))\n",
    "\n",
    "precision = cm[0,0] * 1.0 / (cm[0,0] + cm[1,0])\n",
    "print(\"Precision = %.2f%%\" % (precision * 100))\n",
    "\n",
    "f1 = (2 * precision * recall) / (precision + recall)\n",
    "print(\"F1 Score = %.2f%%\" % (f1 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a5cb97",
   "metadata": {},
   "source": [
    "## 5. (EXTRA) Visualize the logistic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449218e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set= X_train, Y_train\n",
    "\n",
    "X1,X2 = np.meshgrid(np.arange(start =X_set[:, 0].min() -1, stop=X_set[:, 0].max()+1, step = 0.01),\n",
    "                    np.arange(start =X_set[:, 1].min() -1, stop=X_set[:, 1].max()+1, step = 0.01))\n",
    "\n",
    "plt.contourf(X1,X2, logistic_model.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),alpha=0.75, \n",
    "             cmap = ListedColormap(('pink','cyan')))\n",
    "\n",
    "plt.xlim((X1.min(),X1.max()))\n",
    "plt.ylim((X2.min(),X2.max()))\n",
    "\n",
    "for i,j in enumerate(np.unique(y_set)):\n",
    "     plt.scatter(X_set[y_set==j,0], X_set[y_set==j,1], c=ListedColormap(('red','blue'))(i) ,label= j)\n",
    "\n",
    "plt.title('Logistic Regression(Training Set)')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Estimated Salary')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce139c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_set, y_set= X_test, Y_test\n",
    "\n",
    "X1,X2 = np.meshgrid(np.arange(start =X_set[:, 0].min() -1, stop=X_set[:, 0].max()+1, step = 0.01),\n",
    "                    np.arange(start =X_set[:, 1].min() -1, stop=X_set[:, 1].max()+1, step = 0.01))\n",
    "\n",
    "plt.contourf(X1,X2, logistic_model.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),alpha=0.75, \n",
    "             cmap = ListedColormap(('pink','cyan')))\n",
    "\n",
    "plt.xlim((X1.min(),X1.max()))\n",
    "plt.ylim((X2.min(),X2.max()))\n",
    "\n",
    "for i,j in enumerate(np.unique(y_set)):\n",
    "     plt.scatter(X_set[y_set==j,0], X_set[y_set==j,1], c= ListedColormap(('red','blue'))(i) ,label= j) \n",
    "\n",
    "plt.title('Logistic Regression(Test Set)')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Estimated Salary')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
